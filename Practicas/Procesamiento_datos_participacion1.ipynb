{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04c06eb-133f-45b0-bdf2-d8cc86c36228",
   "metadata": {},
   "source": [
    "Participacion 1.\n",
    "### Participación (2 puntos)\n",
    "\n",
    "Una de dos:\n",
    "- Aplicar la técnica de _stem_ o lematización para analizar la frecuencia de palabras de esta obra\n",
    "- Implementar una manera de obtener la frecuencia de $n$-gramas de cualquier obra antes de que se acabe la clase.\n",
    "- Subir la solución propuesta al repositorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffac2d-8b4d-4105-bbcf-ea42da081164",
   "metadata": {},
   "source": [
    "¿Que es la tecnica de lematizacion?\n",
    "- Permite reducir las palabras a sus raíces o formas base, lo que facilita el análisis de frecuencia al agrupar terminos similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456312ec-7077-4292-bbbf-0e2207cec956",
   "metadata": {},
   "source": [
    "Que son los n-gramas? \n",
    "- Son secuencias de caracteres o elementos consecutivos que se extraen de un texto o discurso\n",
    "- Pueden ser: Letras Sílabas Palabras Signos de puntuación Espacios en blanco Fonemas Pares de bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df807b75-5a52-45dc-bddf-c6f207be1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gutenbergpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d445c-b327-4578-a4fe-cc09c58253b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias e imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from gutenbergpy.textget import get_text_by_id, strip_headers\n",
    "import pandas as pd\n",
    "\n",
    "# Stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Descargar el libro de Orgullo y Perjuicio id = 1342\n",
    "def obtener_libro(id=1342):\n",
    "    raw_book = get_text_by_id(id)  # Texto con encabezados\n",
    "    clean_book = strip_headers(raw_book)  # Texto limpio sin encabezados\n",
    "    return clean_book.decode('utf-8'), raw_book.decode('utf-8')  # Decodificar bytes a string para utilizar las librerias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e456a-87f6-4dd1-8773-b61539e5a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el libro\n",
    "clean_book, raw_book = obtener_libro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282a691-1e12-4484-9afc-4fdf3df32655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar el texto - Tokenizar el texto\n",
    "tokens = word_tokenize(clean_book.lower())  # Convertir a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18ce97-5230-4b62-83db-d9fe08863bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar palabras vacías y caracteres no alfabéticos\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d448ae6-e44b-4512-aecc-9026856f1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logica de negocio\n",
    "# Steming\n",
    "stemmer = PorterStemmer()\n",
    "stems = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "# Lemmatización\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "# Frecuencia de palabras\n",
    "frecuencia_palabras_lenmas = Counter(lemmas)  # Usa stems o lemmas según prefieras\n",
    "frecuencia_palabras_stem = Counter(stems) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204005cb-447b-40ec-bdc0-bc964528479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la frecuencia de n-gramas utilizando las palabras tokenizadas\n",
    "# Como segundo parametro es sobre si queremos bigrama, trigramas, etc. El usado en clase fue el n = 2 (bigramas)\n",
    "def obtener_ngramas(tokens, n):\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])  # Genera n-gramas\n",
    "    ngram_freq = Counter(ngrams)\n",
    "    return ngram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96207c6a-bc6a-4292-998d-f777bc6c91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramas = obtener_ngramas(filtered_tokens, 2)\n",
    "print(\"10 Bigramas mas comunes:\")\n",
    "print(bigramas.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660096e0-8976-4bfe-b510-474490fe6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palabras mas comunes\n",
    "print(\"Palabras mas comunes con lenmas:\")\n",
    "print(frecuencia_palabras_lenmas.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3518aa-0090-4be0-99f8-61a34e5f53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palabras mas comunes con lenmas\n",
    "print(\"Palabras mas comunes con stems:\")\n",
    "print(frecuencia_palabras_stem.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8565682-7395-4221-9058-2aa20957ef56",
   "metadata": {},
   "source": [
    "La lematizacion no está alterando mucho las palabras porque ya están en una forma bastante estándar (como \"elizabeth\" y \"darcy\"), \n",
    "El stemmer esta modificando más algunas palabras, como \"darcy\" que se convierte en \"darci\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ee49d-5ff2-4ccb-96cc-d3d1d6c46a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las frecuencias de las palabras más comunes\n",
    "top_lenmas = [count for word, count in frecuencia_palabras_lenmas.most_common(10)]\n",
    "top_stems = [count for word, count in frecuencia_palabras_stem.most_common(10)]\n",
    "words_lenmas = [word for word, count in frecuencia_palabras_lenmas.most_common(10)]\n",
    "words_stems = [word for word, count in frecuencia_palabras_stem.most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101233cc-b121-451d-88b2-978db2cbaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lenmas = pd.DataFrame({'token': words_lenmas, 'conteo': top_lenmas})\n",
    "\n",
    "# Gráfica Lematizadas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_lenmas['token'], df_lenmas['conteo'], color='black')\n",
    "plt.xlabel('Palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Frecuencia de Palabras Lematizadas')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8e188-1b47-4958-8ff6-d0a3b82182e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_stems = pd.DataFrame({'token': words_stems, 'conteo': top_stems})\n",
    "\n",
    "# Grafica de barras Steam\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_stems['token'], df_stems['conteo'], color='orange')\n",
    "plt.xlabel('Palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Frecuencia de Palabras con Stems')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b0426-c0a1-4ce9-9d12-f66c1c3ca977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Barra apiladas\n",
    "df_lenmas = pd.DataFrame({'token': words_lenmas, 'conteo': top_lenmas})\n",
    "df_stems = pd.DataFrame({'token': words_stems, 'conteo': top_stems})\n",
    "\n",
    "# Unir los dos dataframe en uno solo\n",
    "df_combined = pd.DataFrame({\n",
    "    'token': words_lenmas + words_stems,\n",
    "    'conteo': top_lenmas + top_stems,\n",
    "    'tipo': ['Lematizadas'] * len(top_lenmas) + ['Stems'] * len(top_stems)\n",
    "})\n",
    "\n",
    "df_pivot = df_combined.pivot_table(index='token', columns='tipo', values='conteo', aggfunc='sum', fill_value=0)\n",
    "\n",
    "df_pivot.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Configuración del gráfico\n",
    "plt.xlabel('Palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Frecuencia de Palabras: Lematizadas vs Stems (Apilado)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1a404-35a2-4101-8a7d-288b2a7df47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Extraer los 10 bigramas mas comunes, convertirlo a data frame\n",
    "top_bigrams = bigramas.most_common(10)\n",
    "df_bigrams = pd.DataFrame(top_bigrams, columns=['bigram', 'frecuencia'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot de los bigramas más comunes\n",
    "plt.bar([' '.join(bigram) for bigram in df_bigrams['bigram']], df_bigrams['frecuencia'], color='violet')\n",
    "plt.xlabel('Bigramas')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('10 Bigramas Más Comunes')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
